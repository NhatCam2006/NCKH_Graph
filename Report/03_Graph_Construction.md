# Part 3: GRAPH CONSTRUCTION - X√ÇY D·ª∞NG HETEROGENEOUS GRAPH

**File code t∆∞∆°ng ·ª©ng:** `graph_construction.py`  
**Input:** 
- `processed/jobs_processed.csv`
- `processed/job_embeddings.npy`
- `processed/similarity_matrix.npy`

**Output:** 
- `graph_data/hetero_graph.pt`
- `graph_data/entity_mappings.pt`

---

## üìö M·ª§C L·ª§C

1. [Heterogeneous Graph l√† g√¨?](#1-heterogeneous-graph-l√†-g√¨)
2. [Thi·∫øt k·∫ø Graph](#2-thi·∫øt-k·∫ø-graph)
3. [Node Features](#3-node-features)
4. [Edge Construction](#4-edge-construction)
5. [PyTorch Geometric Format](#5-pytorch-geometric-format)
6. [Code chi ti·∫øt](#6-code-chi-ti·∫øt)
7. [FAQ](#7-faq)

---

## 1. HETEROGENEOUS GRAPH L√Ä G√å?

### So s√°nh Homogeneous vs Heterogeneous:

#### Homogeneous Graph:
```
       User1 ---- User2
         |          |
       User3 ---- User4

- 1 lo·∫°i node: User
- 1 lo·∫°i edge: "friend"
```

#### Heterogeneous Graph:
```
    Job1 --posted_by--> Company_A
      |                     |
   located_in            posts
      |                     |
    Hanoi <------------  Job2
            similar_to

- 3 lo·∫°i nodes: Job, Company, Location
- 3 lo·∫°i edges: posted_by, located_in, similar_to
```

### T·∫°i sao d√πng Heterogeneous?

**Rich structure** = More information for GNN!

```python
# Homogeneous: Ch·ªâ c√≥ Job nodes
Job1 --- Job2 --- Job3
# GNN ch·ªâ h·ªçc t·ª´ job-job relationships

# Heterogeneous: Nhi·ªÅu lo·∫°i nodes
Job1 --posted_by--> Company_A
Job1 --located_in--> Hanoi
Job1 --similar_to--> Job2
# GNN h·ªçc t·ª´:
# - Jobs t·ª´ c√πng company c√≥ th·ªÉ li√™n quan
# - Jobs ·ªü c√πng location c√≥ th·ªÉ li√™n quan
# - Similar jobs theo content
```

---

## 2. THI·∫æT K·∫æ GRAPH

### 2.1 Node Types (3 lo·∫°i)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         JOB NODES (500)             ‚îÇ
‚îÇ  - C√°c c√¥ng vi·ªác c·∫ßn tuy·ªÉn          ‚îÇ
‚îÇ  - Features: 399 dims               ‚îÇ
‚îÇ    (embeddings + numerical)         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      COMPANY NODES (343)            ‚îÇ
‚îÇ  - C√°c c√¥ng ty tuy·ªÉn d·ª•ng           ‚îÇ
‚îÇ  - Features: 10 dims                ‚îÇ
‚îÇ    (aggregated statistics)          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      LOCATION NODES (21)            ‚îÇ
‚îÇ  - C√°c ƒë·ªãa ƒëi·ªÉm tuy·ªÉn d·ª•ng          ‚îÇ
‚îÇ  - Features: 8 dims                 ‚îÇ
‚îÇ    (aggregated statistics)          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 2.2 Edge Types (5 lo·∫°i)

```
1. Job --posted_by--> Company  (500 edges)
   M·ªói job ƒë∆∞·ª£c ƒëƒÉng b·ªüi 1 company

2. Company --posts--> Job  (500 edges)
   Reverse edge c·ªßa (1)

3. Job --located_in--> Location  (500 edges)
   M·ªói job ·ªü 1 location

4. Location --has--> Job  (500 edges)
   Reverse edge c·ªßa (3)

5. Job --similar_to--> Job  (4,364 edges)
   Jobs t∆∞∆°ng t·ª± nhau (t·ª´ similarity matrix)
   Bidirectional: n·∫øu A similar B ‚Üí B similar A
```

### 2.3 Graph Structure Diagram

```
                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                  ‚îÇ  Company A   ‚îÇ
                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ posts
                   posted_by
                         ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ                ‚îÇ                ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Job 1  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ Job 2  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ Job 3  ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò similar ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò similar ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ               ‚îÇ                  ‚îÇ
        ‚îÇlocated_in     ‚îÇlocated_in        ‚îÇlocated_in
        ‚îÇ               ‚îÇ                  ‚îÇ
        ‚îÇ           ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îê
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ      Location: Hanoi     ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## 3. NODE FEATURES

### 3.1 Job Node Features (399 dims)

```python
Job features = [
    Text embeddings (384 dims),      # From Part 2
    Salary min (1 dim),              # Normalized
    Salary max (1 dim),              # Normalized
    Experience years (1 dim),        # Normalized
    Quantity (1 dim),                # Log-transformed
    Job type one-hot (~3 dims),      # Categorical
    Company size one-hot (~8 dims)   # Categorical
]
```

#### 3.1.1 Text Embeddings (384 dims)

```python
# Already computed in Part 2
job_embeddings = np.load('job_embeddings.npy')  # (500, 384)
text_features = torch.FloatTensor(job_embeddings)
```

#### 3.1.2 Numerical Features

```python
# Salary (2 dims)
salary_min = df['salary_min'].values  # [18.0, 0.0, 12.0, ...]
salary_max = df['salary_max'].values  # [25.0, 0.0, 16.0, ...]

# Normalize: divide by 100
salary_min = salary_min / 100.0  # Scale down
salary_max = salary_max / 100.0
```

**T·∫°i sao normalize?**
- Original range: 0 - 75,000 (very large!)
- Neural networks prefer values ~ 0-1
- Chia 100: 0 - 750 (still large, but better)

```python
# Experience (1 dim)
experience = df['experience_years'].values  # [3.0, 0.5, 2.0, ...]

# Normalize: divide by 10
experience = experience / 10.0  # 0 - 0.5 range
```

```python
# Quantity (1 dim)
quantity = df['quantity'].values  # [1, 50, 1, 12, ...]

# Log transform (handle large values)
quantity = np.log1p(quantity)  # log(1 + x)
```

**T·∫°i sao log transform?**
- Quantity c√≥ outliers: [1, 1, 1, 50, 1, ...]
- log1p(1) = 0.69
- log1p(50) = 3.93
- ‚Üí Gi·∫£m impact c·ªßa outliers

#### 3.1.3 Categorical Features (One-Hot)

```python
# Job type
job_types = pd.get_dummies(df['Job type'])
# "To√†n th·ªùi gian" ‚Üí [1, 0, 0]
# "B√°n th·ªùi gian" ‚Üí [0, 1, 0]
# ...

# Company size
company_sizes = pd.get_dummies(df['company_size'])
# "25-99 nh√¢n vi√™n" ‚Üí [1, 0, 0, 0, ...]
# "1000+ nh√¢n vi√™n" ‚Üí [0, 1, 0, 0, ...]
# ...
```

#### 3.1.4 Concatenate All

```python
job_features = torch.cat([
    text_embeddings,      # 384
    salary_min,           # 1
    salary_max,           # 1
    experience,           # 1
    quantity,             # 1
    job_type_features,    # ~3
    company_size_features # ~8
], dim=1)

# Result: (500, 399)
```

---

### 3.2 Company Node Features (10 dims)

**Strategy:** Aggregated statistics t·ª´ jobs c·ªßa company ƒë√≥

```python
For each company:
    company_features[idx, 0] = num_jobs          # S·ªë l∆∞·ª£ng jobs
    company_features[idx, 1] = avg_salary_max    # L∆∞∆°ng TB
    company_features[idx, 2] = avg_salary_min
    company_features[idx, 3] = avg_experience    # Kinh nghi·ªám TB
    company_features[idx, 4] = total_quantity    # T·ªïng tuy·ªÉn
    company_features[idx, 5-9] = size_encoding   # Company size
```

**V√≠ d·ª•:**
```python
Company "LG CNS VI·ªÜT NAM":
  - 12 jobs posted
  - Avg salary: 0 (all "Tho·∫£ thu·∫≠n")
  - Avg experience: 2.3 years
  - Total quantity: 15 positions
  - Size: 1000+ nh√¢n vi√™n ‚Üí [0,0,0,0,1]
```

**Code:**
```python
def _create_company_features(self) -> torch.Tensor:
    n_companies = len(self.company_mapping)
    company_features = torch.zeros(n_companies, 10)
    
    for company, company_idx in self.company_mapping.items():
        # Get all jobs from this company
        company_jobs = self.df[self.df['Name company'] == company]
        
        # Aggregated features
        company_features[company_idx, 0] = len(company_jobs)
        company_features[company_idx, 1] = company_jobs['salary_max'].mean()
        company_features[company_idx, 2] = company_jobs['salary_min'].mean()
        company_features[company_idx, 3] = company_jobs['experience_years'].mean()
        company_features[company_idx, 4] = company_jobs['quantity'].sum()
        # ... size encoding ...
    
    # Normalize
    company_features[:, 1:5] = company_features[:, 1:5] / (company_features[:, 1:5].max(dim=0)[0] + 1e-8)
    
    return company_features
```

---

### 3.3 Location Node Features (8 dims)

**Strategy:** T∆∞∆°ng t·ª± Company, aggregate t·ª´ jobs t·∫°i location ƒë√≥

```python
For each location:
    location_features[idx, 0] = num_jobs          # S·ªë jobs
    location_features[idx, 1] = avg_salary_max    # L∆∞∆°ng TB
    location_features[idx, 2] = avg_salary_min
    location_features[idx, 3] = avg_experience    # Kinh nghi·ªám TB
    location_features[idx, 4] = total_quantity    # T·ªïng tuy·ªÉn
    location_features[idx, 5-7] = reserved        # Future use
```

**V√≠ d·ª•:**
```python
Location "H√† N·ªôi":
  - 233 jobs
  - Avg salary max: 848 tri·ªáu
  - Avg salary min: 420 tri·ªáu
  - Avg experience: 2.1 years
  - Total quantity: 312 positions
```

---

## 4. EDGE CONSTRUCTION

### 4.1 Job ‚Üí Company Edges

```python
# For each job, link to its company
job_company_edges = []
for idx, row in df.iterrows():
    job_idx = job_mapping[row['JobID']]        # J001 ‚Üí 0
    company_idx = company_mapping[row['Name company']]  # "C√îNG TY..." ‚Üí 15
    job_company_edges.append([job_idx, company_idx])

edge_index = torch.tensor(job_company_edges).t()
# Shape: (2, 500)
# [[0,    1,    2,    ...]  ‚Üê job indices
#  [15,   20,   15,   ...]] ‚Üê company indices
```

**Format gi·∫£i th√≠ch:**
```
Edge (i, j) means: Job i --posted_by--> Company j

Edge list:
[0, 15] ‚Üí Job 0 posted by Company 15
[1, 20] ‚Üí Job 1 posted by Company 20
[2, 15] ‚Üí Job 2 posted by Company 15 (same company as Job 0!)
```

### 4.2 Company ‚Üí Job Edges (Reverse)

```python
# Simply flip the edge_index
edges[('company', 'posts', 'job')] = edges[('job', 'posted_by', 'company')].flip(0)

# [[15,   20,   15,   ...]  ‚Üê company indices
#  [0,    1,    2,    ...]] ‚Üê job indices
```

**T·∫°i sao c·∫ßn reverse edges?**

GNN message passing c·∫ßn **bidirectional** information flow:
- Job ‚Üí Company: "Job n√†y thu·ªôc company g√¨?"
- Company ‚Üí Job: "Company n√†y c√≥ jobs n√†o?"

### 4.3 Job ‚Üí Location Edges

```python
# Similar to Job ‚Üí Company
job_location_edges = []
for idx, row in df.iterrows():
    job_idx = job_mapping[row['JobID']]
    location_idx = location_mapping[row['location_clean']]
    job_location_edges.append([job_idx, location_idx])

edge_index = torch.tensor(job_location_edges).t()
# Shape: (2, 500)
```

### 4.4 Job ‚Üî Job Similarity Edges

**Key idea:** S·ª≠ d·ª•ng similarity matrix t·ª´ Part 2

```python
def _find_similar_jobs(self) -> List[Tuple[int, int, float]]:
    threshold = 0.6
    top_k = 10
    
    n_jobs = self.similarity_matrix.shape[0]
    edges = []
    
    for i in range(n_jobs):
        sims = self.similarity_matrix[i].copy()
        sims[i] = -1  # Exclude self
        
        # Top-K most similar
        top_indices = np.argsort(sims)[-top_k:][::-1]
        
        for j in top_indices:
            if sims[j] >= threshold and i < j:
                edges.append((i, j, float(sims[j])))
    
    return edges  # 2,182 pairs
```

**Convert to bidirectional:**
```python
# Create bidirectional edges
job_job_edges = [[i, j] for (i, j, sim) in similar_pairs]
job_job_edges_reverse = [[j, i] for (i, j, sim) in similar_pairs]

all_edges = job_job_edges + job_job_edges_reverse
# 2,182 √ó 2 = 4,364 edges

edge_index = torch.tensor(all_edges).t()
# Shape: (2, 4364)
```

**T·∫°i sao bidirectional?**
- Similarity l√† symmetric: sim(A, B) = sim(B, A)
- GNN c·∫ßn c·∫£ 2 directions ƒë·ªÉ message passing

---

## 5. PYTORCH GEOMETRIC FORMAT

### 5.1 HeteroData Object

```python
from torch_geometric.data import HeteroData

graph = HeteroData()
```

**HeteroData** = Container cho heterogeneous graph

### 5.2 Add Node Features

```python
# Add job nodes
graph['job'].x = job_features  # (500, 399)

# Add company nodes
graph['company'].x = company_features  # (343, 10)

# Add location nodes
graph['location'].x = location_features  # (21, 8)
```

**Syntax:**
```python
graph[node_type].x = features
```

### 5.3 Add Edges

```python
# Add job ‚Üí company edges
graph[('job', 'posted_by', 'company')].edge_index = job_company_edge_index

# Add reverse edges
graph[('company', 'posts', 'job')].edge_index = company_job_edge_index

# Add job ‚Üí location edges
graph[('job', 'located_in', 'location')].edge_index = job_location_edge_index

# Add reverse edges
graph[('location', 'has', 'job')].edge_index = location_job_edge_index

# Add job ‚Üî job edges
graph[('job', 'similar_to', 'job')].edge_index = job_job_edge_index
```

**Syntax:**
```python
graph[(src_type, relation, dst_type)].edge_index = edge_index
```

### 5.4 Add Metadata

```python
# Store entity names for later reference
graph['job'].job_ids = list(job_mapping.keys())
graph['company'].company_names = list(company_mapping.keys())
graph['location'].location_names = list(location_mapping.keys())
```

### 5.5 Final Graph Structure

```python
HeteroData(
  job={
    x=[500, 399],           # Features
    job_ids=[500],          # Metadata
  },
  company={
    x=[343, 10],
    company_names=[343],
  },
  location={
    x=[21, 8],
    location_names=[21],
  },
  (job, posted_by, company)={ edge_index=[2, 500] },
  (company, posts, job)={ edge_index=[2, 500] },
  (job, located_in, location)={ edge_index=[2, 500] },
  (location, has, job)={ edge_index=[2, 500] },
  (job, similar_to, job)={ edge_index=[2, 4364] }
)
```

---

## 6. CODE CHI TI·∫æT

### Main Pipeline

```python
class HeterogeneousJobGraph:
    def build_graph(self) -> HeteroData:
        # Step 1: Create entity mappings
        self._create_entity_mappings()
        
        # Step 2: Create node features
        self.job_features = self._create_job_features()
        self.company_features = self._create_company_features()
        self.location_features = self._create_location_features()
        
        # Step 3: Create edges
        edges_dict = self._create_edges()
        
        # Step 4: Build HeteroData
        graph = HeteroData()
        
        # Add nodes
        graph['job'].x = self.job_features
        graph['company'].x = self.company_features
        graph['location'].x = self.location_features
        
        # Add edges
        for edge_type, edge_index in edges_dict.items():
            graph[edge_type].edge_index = edge_index
        
        # Add metadata
        graph['job'].job_ids = list(self.job_mapping.keys())
        graph['company'].company_names = list(self.company_mapping.keys())
        graph['location'].location_names = list(self.location_mapping.keys())
        
        return graph
```

### Save Graph

```python
def save_graph(self, path: str = "graph_data/hetero_graph.pt"):
    torch.save(self.graph, path)
    print(f"Graph saved to {path}")
    
    # Also save mappings
    mappings = {
        'job_mapping': self.job_mapping,
        'company_mapping': self.company_mapping,
        'location_mapping': self.location_mapping
    }
    torch.save(mappings, "graph_data/entity_mappings.pt")
```

---

## 7. FAQ

### Q1: T·∫°i sao c·∫ßn reverse edges?
**A:** GNN message passing l√† **directional**:
```python
# Without reverse:
Job ‚Üí Company  # Job can receive info from Company? NO!

# With reverse:
Job ‚Üí Company
Company ‚Üí Job  # Now both can exchange information ‚úì
```

### Q2: Edge features c√≥ c·∫ßn kh√¥ng?
**A:** Optional! Hi·ªán t·∫°i ch·ªâ c√≥ edge_index (structural info)
```python
# C√≥ th·ªÉ th√™m edge features:
graph[('job', 'similar_to', 'job')].edge_attr = similarity_scores

# GNN c√≥ th·ªÉ d√πng edge features ƒë·ªÉ weight message passing
```

### Q3: T·∫°i sao Job features 399 dims, Company ch·ªâ 10?
**A:** 
- Jobs: C√≥ rich text ‚Üí embeddings 384 dims
- Companies: Ch·ªâ c√≥ aggregated stats ‚Üí 10 dims ƒë·ªß
- GNN s·∫Ω h·ªçc update company representations t·ª´ connected jobs!

### Q4: Graph n√†y c√≥ th·ªÉ scale kh√¥ng?
**A:** YES!
```python
Current: 500 jobs ‚Üí 0.77 MB
Scale to: 10,000 jobs ‚Üí ~15 MB (linear scaling)
          100,000 jobs ‚Üí ~150 MB (still manageable!)
```

### Q5: C√≥ th·ªÉ th√™m node types kh√°c kh√¥ng?
**A:** Ho√†n to√†n ƒë∆∞·ª£c!
```python
# C√≥ th·ªÉ th√™m:
- Skill nodes (extracted from requirements)
- Industry nodes
- User nodes (for recommendation)
- ...

# Simply add to HeteroData:
graph['skill'].x = skill_features
graph[('job', 'requires', 'skill')].edge_index = ...
```

### Q6: Format n√†y c√≥ t∆∞∆°ng th√≠ch v·ªõi DGL kh√¥ng?
**A:** PyTorch Geometric v√† DGL l√† 2 frameworks kh√°c nhau
```python
# PyTorch Geometric (hi·ªán t·∫°i)
from torch_geometric.data import HeteroData

# DGL (n·∫øu mu·ªën convert)
import dgl
dgl_graph = dgl.heterograph({...})
```

C√≥ th·ªÉ convert qua l·∫°i, nh∆∞ng PyG l√† standard cho research.

---

## üìå T√ìM T·∫ÆT

**Input:** 
- Processed CSV
- Job embeddings
- Similarity matrix

**Process:**
1. ‚úÖ Define 3 node types: Job, Company, Location
2. ‚úÖ Create rich features for each node type
3. ‚úÖ Build 5 edge types (including reverses)
4. ‚úÖ Format as PyTorch Geometric HeteroData

**Output:**
- `hetero_graph.pt`: Complete graph (0.77 MB)
- `entity_mappings.pt`: ID mappings

**Graph statistics:**
- Nodes: 864 (500 + 343 + 21)
- Edges: 6,364 (500 + 500 + 500 + 500 + 4,364)
- Density: 1.7% (sparse, good for GNN!)

---

**üëâ Ti·∫øp theo: [Part 4: Visualization](04_Visualization.md)**

---

*Part 3 - Graph Construction | NCKH Project*
